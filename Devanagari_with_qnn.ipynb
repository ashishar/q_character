{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashishar/q_character/blob/main/Devanagari_with_qnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlUHdpeR9L6F",
        "outputId": "68680a65-0dd4-4c48-84da-88513a240369"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torchvision is already installed.\n"
          ]
        }
      ],
      "source": [
        "# !pip install torchvision\n",
        "# !pip install qiskit-machine-learning\n",
        "import importlib\n",
        "\n",
        "# Check if torchvision is installed\n",
        "try:\n",
        "    importlib.import_module('torchvision')\n",
        "    print(\"torchvision is already installed.\")\n",
        "except ImportError:\n",
        "    print(\"torchvision is not installed. Installing...\")\n",
        "    # Install torchvision using pip\n",
        "    try:\n",
        "        import pip\n",
        "        pip.main(['install', 'torchvision'])\n",
        "        print(\"torchvision installed successfully.\")\n",
        "    except Exception as e:\n",
        "        print(\"Error occurred while installing torchvision:\", str(e))\n",
        "\n",
        "# try:\n",
        "#     importlib.import_module('qiskit')\n",
        "#     print(\"qiskit is already installed.\")\n",
        "# except ImportError:\n",
        "#     print(\"qiskit is not installed. Installing...\")\n",
        "#     # Install torchvision using pip\n",
        "#     try:\n",
        "#         import pip\n",
        "#         pip.main(['install', 'qiskit'])\n",
        "#         print(\"qiskit installed successfully.\")\n",
        "#     except Exception as e:\n",
        "#         print(\"Error occurred while installing qiskit:\", str(e))\n",
        "\n",
        "# try:\n",
        "#     importlib.import_module('qiskit_machine_learning')\n",
        "#     print(\"qiskit-machine-learning is already installed.\")\n",
        "# except ImportError:\n",
        "#     print(\"qiskit-machine-learning is not installed. Installing...\")\n",
        "#     # Install torchvision using pip\n",
        "#     try:\n",
        "#         import pip\n",
        "#         pip.main(['install', 'qiskit-machine-learning'])\n",
        "#         print(\"qiskit-machine-learning installed successfully.\")\n",
        "#     except Exception as e:\n",
        "#         print(\"Error occurred while installing qiskit-machine-learning:\", str(e))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Change directory to the desired location where the file is stored.\n",
        "%cd /content/drive/MyDrive/\n",
        "\n",
        "# Import the file named quantum_circuit_simulator.py\n",
        "import quantum_circuit_simulator\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeGiH98DbAsy",
        "outputId": "3ebd09b6-bfc3-42e0-edd2-91f37eef54a5"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: I want to download devanagari character dataset from Kaggle.\n",
        "\n",
        "#!pip install kaggle\n",
        "#!mkdir -p ~/.kaggle\n",
        "#!cp /content/drive/MyDrive/devanagari/kaggle.json ~/.kaggle/kaggle.json\n",
        "#!kaggle datasets download --force -d rishianand/devanagari-character-set\n",
        "!unzip \"/content/drive/My Drive/devanagari-character-set.zip\" -d \"/content/data\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ip8-RV8ec6Z8",
        "outputId": "0740b9d0-49f0-4bdc-a559-cd9ee677bae4"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/My Drive/devanagari-character-set.zip\n",
            "replace /content/data/Images/Images/character_01_ka/10962.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Pillow\n",
        "\n",
        "def crop_images(dataset):\n",
        "    # Calculating start and end indices for the crop\n",
        "    start = (32 - 28) // 2  # (32 - 28) / 2 = 2\n",
        "    end = start + 28  # 2 + 28 = 30\n",
        "\n",
        "    # Cropping to get 28x28 images\n",
        "    # dataset[:, start:end, start:end] would be the sliced tensor\n",
        "    return dataset[:, start:end, start:end]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1L1wbE6EZB59",
        "outputId": "850ff332-104e-4223-a968-95b6acba6bd8"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.utils.data import Subset\n",
        "from torch.utils.data import DataLoader, random_split, Subset\n",
        "from torchvision import transforms\n",
        "from torch import nn\n",
        "\n",
        "# Load the CSV file\n",
        "data = pd.read_csv('/content/data/data.csv')\n",
        "\n",
        "# Convert all columns to numeric, coercing errors and handling non-numeric data\n",
        "#data = data.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "\n",
        "# Fill NaN values with 0 (consider other strategies depending on your context)\n",
        "#data = data.fillna(0)\n",
        "\n",
        "# Assume images are 28x28 pixels, update this based on your actual image dimensions\n",
        "image_height = 32\n",
        "image_width = 32\n",
        "\n",
        "# Separate features and labels\n",
        "features = data.iloc[:, :-1]  # All rows, all columns except the last one\n",
        "features.head()\n",
        "# column_sums = features.sum()\n",
        "# print(column_sums)\n",
        "\n",
        "# Fill missing values if any\n",
        "#features = features.fillna(0)\n",
        "\n",
        "features_images = features.values.reshape(-1, 32, 32)\n",
        "labels = data.iloc[:, -1]     # All rows, only the last column\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "labels_encoded = label_encoder.fit_transform(labels)\n",
        "\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "features_tensor = torch.tensor(features_images, dtype=torch.float32)\n",
        "# Cropping the images\n",
        "cropped_features_tensor = crop_images(features_tensor)\n",
        "\n",
        "labels_tensor = torch.tensor(labels_encoded, dtype=torch.long)\n",
        "\n",
        "print(\"cropped features\", cropped_features_tensor.shape)\n",
        "# Resize all images\n",
        "#resized_images = torch.stack([resize_image(img) for img in features_tensor])\n",
        "#resized_images_squeezed=resized_images.squeeze(1)\n",
        "#print(\"resized_tensor\", resized_images_squeezed.shape)\n",
        "\n",
        "# Convert DataFrame to PyTorch tensors\n",
        "# features_tensor = torch.tensor(features.values, dtype=torch.float32)\n",
        "# labels_tensor = torch.tensor(labels.values, dtype=torch.long)\n",
        "\n",
        "# Create a TensorDataset to be used with a DataLoader\n",
        "dataset = TensorDataset(cropped_features_tensor, labels_tensor)\n",
        "\n",
        "# Generate a random permutation of indices and select the first 1000\n",
        "indices = torch.randperm(len(dataset))[:1000]\n",
        "\n",
        "# Create a subset with these indices\n",
        "subset = Subset(dataset, indices)\n",
        "\n",
        "# Split the subset into training and testing datasets (80-20 split)\n",
        "num_train = int(0.7 * len(subset))  # 80% for training\n",
        "num_test = len(subset) - num_train  # Remaining 20% for testing\n",
        "\n",
        "train_dataset, test_dataset = random_split(subset, [num_train, num_test])\n",
        "# def reshape_dataset(dataset, new_shape):\n",
        "#     reshaped_features = [features.view(new_shape) for features, _ in dataset]\n",
        "#     labels = [labels for _, labels in dataset]\n",
        "#     features_tensor = torch.stack(reshaped_features)\n",
        "#     labels_tensor = torch.stack(labels)\n",
        "#     return TensorDataset(features_tensor, labels_tensor)\n",
        "\n",
        "# # Reshape the datasets to 32x32\n",
        "# train_dataset_reshaped = reshape_dataset(train_dataset, (-1, 32, 32))\n",
        "# test_dataset_reshaped = reshape_dataset(test_dataset, (-1, 32, 32))\n",
        "\n",
        "# Create DataLoaders for train and test sets\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Example usage\n",
        "# for features, labels in train_loader:\n",
        "#     # Training loop code here\n",
        "#     print(\"Training batch features:\", features.size())\n",
        "#     print(\"Training batch labels:\", labels.size())\n",
        "\n",
        "# for features, labels in test_loader:\n",
        "#     # Testing loop code here\n",
        "    # print(\"Testing batch features:\", features.size())\n",
        "    # print(\"Testing batch labels:\", labels.size())\n",
        "\n",
        "# Create a DataLoader to handle batching\n",
        "#dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpN0fqKy9zGZ",
        "outputId": "c53e048c-a269-469d-a652-1234c40181b7"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cropped features torch.Size([92000, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting function\n",
        "def plot_images(images, labels, num_images=5):\n",
        "  fig, axes = plt.subplots(1, num_images, figsize=(10, 2))\n",
        "  for i, ax in enumerate(axes):\n",
        "    ax.imshow(images[i], cmap='gray')\n",
        "    ax.set_title(f'Label: {labels[i]}')\n",
        "    ax.axis('on')\n",
        "  plt.show()\n",
        "\n",
        "# Display the first 5 images and labels\n",
        "for features, labels in train_loader:\n",
        "  plot_images(features, labels, 5)\n",
        "  break  # Only process the first batch#\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "RQcQp2F5SXnN",
        "outputId": "d3dbea55-3fb0-46ac-cb0a-74a45f30c9c6"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x200 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for features, labels in train_loader:\n",
        "  print(features.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S47c9-faRHiI",
        "outputId": "c266d75b-4826-468d-e744-d7656fe75f21"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 28, 28])\n",
            "torch.Size([64, 28, 28])\n",
            "torch.Size([64, 28, 28])\n",
            "torch.Size([64, 28, 28])\n",
            "torch.Size([64, 28, 28])\n",
            "torch.Size([64, 28, 28])\n",
            "torch.Size([64, 28, 28])\n",
            "torch.Size([64, 28, 28])\n",
            "torch.Size([64, 28, 28])\n",
            "torch.Size([64, 28, 28])\n",
            "torch.Size([60, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "from IPython.display import display, clear_output\n",
        "import time\n",
        "\n",
        "\n",
        "def plot_images_by_label(dataloader, specific_label, num_images=5):\n",
        "    count = 0  # Counter to track how many images we have displayed\n",
        "    plt.figure(figsize=(10, 2))  # Set up the figure size\n",
        "\n",
        "    for images, labels in dataloader:\n",
        "        for image, label in zip(images, labels):\n",
        "            if label.item() == specific_label:  # Check if the label matches\n",
        "                count += 1\n",
        "                ax = plt.subplot(1, num_images, count)  # Create a subplot for each image\n",
        "                ax.imshow(image.squeeze(), cmap='gray')  # Display image, squeeze() is used to remove extra dimensions if any\n",
        "                ax.title.set_text(f'Label: {label.item()}')\n",
        "                ax.axis('on')  # Turn off axis\n",
        "\n",
        "                if count == num_images:  # Only display a specific number of images\n",
        "                    plt.show()\n",
        "                    return\n",
        "# Example usage\n",
        "# Assuming your DataLoader, images, and labels are properly set up\n",
        "# Here you call the function with the label you want to display and the number of images\n",
        "\n",
        "for i in range(2):\n",
        "  plot_images_by_label(train_loader, specific_label=i, num_images=5)# Call the function with the desired label\n",
        "  clear_output(wait=True)  # Clear the current output and wait for new output\n",
        "  time.sleep(0.01)  # Pause for a second to simulate time taken in an iteration\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "gePTI1133A1-",
        "outputId": "7c936bda-8bf9-4cd5-809c-32500538ca56"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-e3fe6977670b>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m46\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m   \u001b[0mplot_images_by_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecific_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_images\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# Call the function with the desired label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m   \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Clear the current output and wait for new output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Pause for a second to simulate time taken in an iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-97-e3fe6977670b>\u001b[0m in \u001b[0;36mplot_images_by_label\u001b[0;34m(dataloader, specific_label, num_images)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnum_images\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only display a specific number of images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Example usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m     \"\"\"\n\u001b[1;32m    445\u001b[0m     \u001b[0m_warn_if_gui_out_of_main_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_get_backend_mod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib_inline/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfigure_manager\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mGcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_fig_managers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             display(\n\u001b[0m\u001b[1;32m     91\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-2>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mFigureCanvasBase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2364\u001b[0m                 \u001b[0;31m# force the figure dpi to 72), so we need to set it again here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2366\u001b[0;31m                     result = print_method(\n\u001b[0m\u001b[1;32m   2367\u001b[0m                         \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2368\u001b[0m                         \u001b[0mfacecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfacecolor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2230\u001b[0m                 \"bbox_inches_restore\"}\n\u001b[1;32m   2231\u001b[0m             \u001b[0mskip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptional_kws\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2232\u001b[0;31m             print_method = functools.wraps(meth)(lambda *args, **kwargs: meth(\n\u001b[0m\u001b[1;32m   2233\u001b[0m                 *args, **{k: v for k, v in kwargs.items() if k not in skip}))\n\u001b[1;32m   2234\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Let third-parties do as they see fit.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0;34m*\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincluding\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0;34m'Software'\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \"\"\"\n\u001b[0;32m--> 509\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print_pil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"png\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpil_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprint_to_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36m_print_pil\u001b[0;34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[0m\n\u001b[1;32m    455\u001b[0m         *pil_kwargs* and *metadata* are forwarded).\n\u001b[1;32m    456\u001b[0m         \"\"\"\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0mFigureCanvasAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m         mpl.image.imsave(\n\u001b[1;32m    459\u001b[0m             \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"upper\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    398\u001b[0m              (self.toolbar._wait_cursor_for_draw_cm() if self.toolbar\n\u001b[1;32m    399\u001b[0m               else nullcontext()):\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0;31m# A GUI class may be need to update a window using this draw, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;31m# don't forget to call the superclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rasterizing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3139\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3140\u001b[0;31m             mimage._draw_list_compositing_images(\n\u001b[0m\u001b[1;32m   3141\u001b[0m                 renderer, self, artists, self.suppressComposite)\n\u001b[1;32m   3142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3026\u001b[0m                 \u001b[0martists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3028\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_title_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3030\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxison\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_update_title_position\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   2970\u001b[0m                 \u001b[0mtop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mymax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2972\u001b[0;31m                     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# update offsetText\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2973\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffsetText\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2974\u001b[0m                         \u001b[0mbb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffsetText\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[0;34m(self, renderer, for_layout_only)\u001b[0m\n\u001b[1;32m   1323\u001b[0m         \u001b[0mticks_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1325\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_label_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m         \u001b[0;31m# go back to just this axis's tick labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_update_label_position\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   2563\u001b[0m         \u001b[0;31m# get bounding boxes for this axis and any siblings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2564\u001b[0m         \u001b[0;31m# that have been set by `fig.align_ylabels()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2565\u001b[0;31m         \u001b[0mbboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbboxes2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tick_boxes_siblings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2566\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2567\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_position\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'left'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_get_tick_boxes_siblings\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   2098\u001b[0m             \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{axis_name}axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2099\u001b[0m             \u001b[0mticks_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2100\u001b[0;31m             \u001b[0mtlb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtlb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_ticklabel_bboxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticks_to_draw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2101\u001b[0m             \u001b[0mbboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtlb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m             \u001b[0mbboxes2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtlb2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_get_ticklabel_bboxes\u001b[0;34m(self, ticks, renderer)\u001b[0m\n\u001b[1;32m   1302\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrenderer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m             \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return ([tick.label1.get_window_extent(renderer)\n\u001b[0m\u001b[1;32m   1305\u001b[0m                  for tick in ticks if tick.label1.get_visible()],\n\u001b[1;32m   1306\u001b[0m                 [tick.label2.get_window_extent(renderer)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1302\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrenderer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m             \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return ([tick.label1.get_window_extent(renderer)\n\u001b[0m\u001b[1;32m   1305\u001b[0m                  for tick in ticks if tick.label1.get_visible()],\n\u001b[1;32m   1306\u001b[0m                 [tick.label2.get_window_extent(renderer)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/text.py\u001b[0m in \u001b[0;36mget_window_extent\u001b[0;34m(self, renderer, dpi)\u001b[0m\n\u001b[1;32m    960\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_unitless_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m             \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    963\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/transforms.py\u001b[0m in \u001b[0;36mtranslated\u001b[0;34m(self, tx, ty)\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mBbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mtranslated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m         \u001b[0;34m\"\"\"Construct a `Bbox` by translating this one by *tx* and *ty*.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mBbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_points\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"    # Get gpu or cpu device for training\n",
        "print(f\"Using {device} device\\n\")\n",
        "\n",
        "import torchvision.transforms.functional as TF\n",
        "from skimage.feature import hog\n",
        "from quantum_circuit_simulator import quantum_circuit\n",
        "\n",
        "\n",
        "# Define a function to compute HOG features for an image\n",
        "def compute_hog_features(image):\n",
        "    features, _ = hog(image, orientations=10, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True)\n",
        "\n",
        "    return features\n",
        "\n",
        "#=====================================================================================\n",
        "\n",
        "\n",
        "class QNN(torch.nn.Module):                              # Define model\n",
        "    def __init__(self, n, L):                            # number of qubits = n, number of quantum layers = L\n",
        "        super().__init__()\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        angles = torch.empty((L, n), dtype=torch.float64)\n",
        "        torch.nn.init.uniform_(angles, -0.01, 0.01)\n",
        "        self.angles = torch.nn.Parameter(angles)                   # it makes angles learnable parameters\n",
        "\n",
        "        # self.fc1 = nn.Linear(1024, 1024)\n",
        "        # self.fc2 = nn.Linear(784,512)\n",
        "        # self.fc3 = nn.Linear(512, 1024)\n",
        "\n",
        "        self.linear = nn.Linear(2**n, 46)                          # classical linear layer\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        #x = F.pad(x, (2 ,2, 2, 2), \"constant\", 0)                  # (left, right, top, bottom) padding\n",
        "        x_projection = torch.sum(x, dim=1).to(device)  # Calculate x-axis projection\n",
        "        #x_projection = x_projection / torch.norm(x_projection, p=1)\n",
        "        y_projection = torch.sum(x, dim=2).to(device)  # Calculate x-axis projection\n",
        "        #y_projection = y_projection / torch.norm(y_projection, p=1)\n",
        "        #angle projection\n",
        "        rotated_images1 = TF.rotate(x,30).to(device)\n",
        "        rotated_images2 = TF.rotate(x,45).to(device)\n",
        "        rotated_images3 = TF.rotate(x,60).to(device)\n",
        "\n",
        "        #rotated projections\n",
        "        rotated_projection1=torch.sum(rotated_images1, dim=2).to(device)\n",
        "        rotated_projection2=torch.sum(rotated_images2, dim=2).to(device)\n",
        "        rotated_projection3=torch.sum(rotated_images3, dim=2).to(device)\n",
        "\n",
        "        #rotated_images = torch.sum(torch.stack([TF.rotate(img, angle) for img in inputs]))\n",
        "        x_image=x.cpu().numpy()\n",
        "        hog_features = [compute_hog_features(np.squeeze(image)) for image in x_image]\n",
        "        hog_features_tensor = torch.tensor(np.array(hog_features), dtype=torch.float32).to(device)\n",
        "        #print(hog_features_tensor.shape)\n",
        "\n",
        "        x = self.flatten(x)\n",
        "        x = x[:, :-32]\n",
        "\n",
        "        # print(\"sizes \",x.shape, y_projection.shape, rotated_projection1.shape,rotated_projection2.shape,\n",
        "        #      rotated_projection3.shape,hog_features_tensor.shape)\n",
        "\n",
        "        combined_projection=torch.cat((x,y_projection.squeeze(), rotated_projection1.squeeze(),rotated_projection2.squeeze(),rotated_projection3.squeeze(),hog_features_tensor), dim=1)\n",
        "\n",
        "        #print(\"combined \", combined_projection.shape)\n",
        "        #x = self.flatten(x)\n",
        "        combined_projection /= torch.linalg.norm(x.clone(), ord=2, dim=1, keepdim=True)   # L2 normalization to change x --> |x\n",
        "\n",
        "        # combined_projection = torch.sigmoid(self.fc1(combined_projection))\n",
        "        # x1 = torch.sigmoid(self.fc2(x1))\n",
        "        # x1 = torch.sigmoid(self.fc3(x1))\n",
        "\n",
        "        '''initializing parameterized quantum circuits (PQC)'''\n",
        "\n",
        "        qc = quantum_circuit(num_qubits = n, state_vector = combined_projection.T)   # each column is a feature-vector of an example\n",
        "        for l in range(L):\n",
        "            qc.Ry_layer(self.angles[l].to(torch.cfloat))           # rotation part of lth quantum layer\n",
        "            qc.cx_linear_layer()                                   # entangling part of lth quantum layer\n",
        "\n",
        "        'after passing through the PQC, measurement on the output-ket in the computational basis'\n",
        "        x = torch.real(qc.probabilities())               # each column is a probabilities-vector for an example\n",
        "                                                         # x.shape = (dim, batch size)\n",
        "\n",
        "        #print(torch.sum(x, dim=0))                      # to see whether probabilities add up to 1 or not\n",
        "\n",
        "        x = self.linear(x.T)                             # x.shape = (batch size, 10),  classical linear layer\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "Kulr9lBq_jxr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79e79859-df37-47c7-8233-95f8d7e6b352"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def performance_estimate(dataset, model, loss_fn, train_or_test):\n",
        "    '''this function computes accuracy and loss of a model on the training or test set'''\n",
        "    data_size = len(dataset)\n",
        "\n",
        "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n",
        "    num_batches = len(dataloader)\n",
        "\n",
        "    model.eval()\n",
        "    loss, accuracy = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            accuracy += (pred.argmax(1) == y).sum().item()\n",
        "            loss += loss_fn(pred, y).item()\n",
        "    accuracy /= data_size                                            # accuracy lies in the interval [0, 1]\n",
        "    loss /= num_batches\n",
        "    print(f\"{train_or_test} accuracy: {round(accuracy, 3)},  {train_or_test} loss: {round(loss,3)}\")\n",
        "    return accuracy, loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def one_epoch(model, loss_fn, optimizer, train_dataset, test_dataset, batch_size):\n",
        "\n",
        "    A_train, L_train, A_test, L_test = [], [], [], []\n",
        "\n",
        "    dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        out = model(X)                             # Perform a single forward pass\n",
        "        loss = loss_fn(out, y)\n",
        "\n",
        "        optimizer.zero_grad()                      # Clear gradients\n",
        "        loss.backward()                            # Derive gradients, backpropagation\n",
        "        optimizer.step()                           # Update parameters based on gradients\n",
        "\n",
        "\n",
        "        if batch % batch_size == 0:\n",
        "            #As training progress, computing and appending loss and accuracy of the model on train and test set\n",
        "            accuracy_train, loss_train = performance_estimate(train_dataset, model, loss_fn, 'train')\n",
        "            accuracy_test, loss_test = performance_estimate(test_dataset, model, loss_fn, 'test ')\n",
        "            print()\n",
        "\n",
        "            A_train.append(accuracy_train)\n",
        "            L_train.append(loss_train)\n",
        "            A_test.append(accuracy_test)\n",
        "            L_test.append(loss_test)\n",
        "\n",
        "            #print(f\"train loss: {round(loss,3)}\")\n",
        "\n",
        "    return A_train, L_train, A_test, L_test\n",
        "\n",
        "\n",
        "\n",
        "def training(train_dataset, test_dataset, batch_size, n, L, lr_, weight_decay_, epochs):\n",
        "\n",
        "    model = QNN(n=n, L=L).to(device)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr_, weight_decay=weight_decay_)\n",
        "\n",
        "    A_Train, L_Train, A_Test, L_Test = [], [], [], []\n",
        "    for t in range(epochs):\n",
        "        print(f\"Epoch {t+1} ---------------------------------- \\n\")\n",
        "        #As training progress, computing and appending loss and accuracy of the model on train and test set\n",
        "        A_train, L_train, A_test, L_test = one_epoch(model, loss_fn, optimizer, train_dataset, test_dataset, batch_size)\n",
        "        A_Train += A_train\n",
        "        L_Train += L_train\n",
        "        A_Test += A_test\n",
        "        L_Test += L_test\n",
        "\n",
        "        #accuracy, loss = performance_estimate(test_dataset, model, loss_fn, 'test ')\n",
        "\n",
        "    model_state_dict = model.state_dict()           # for saving or loading the trained model\n",
        "\n",
        "    return A_Train, L_Train, A_Test, L_Test, model_state_dict"
      ],
      "metadata": {
        "id": "VYomaJwMBp2m"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "n = 10\n",
        "dim = 2**n              # dimension of the n-qubit Hilbert space\n",
        "L = 2\n",
        "\n",
        "n_angs = n*L\n",
        "\n",
        "print(\"number of qubits = \", n)\n",
        "print(\"number of quantum layers = \", L)\n",
        "print(f\"number of angles (learnable parameters of quantum circuit) = {n_angs}\\n \")\n",
        "\n",
        "#--------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "batch_size = 64\n",
        "print(f'batch_size = {batch_size}\\n')\n",
        "\n",
        "\n",
        "#----------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "A_Train, L_Train, A_Test, L_Test, model_state_dict = training(train_dataset, test_dataset, batch_size=batch_size, n=n, L=L,\n",
        "                                                              lr_=0.01, weight_decay_=1e-10, epochs=30)\n",
        "\n",
        "\n",
        "print(f' ~~~~~ training is done ~~~~~\\n')"
      ],
      "metadata": {
        "id": "Ogr-wkCNBuJl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff6b17ec-301a-45d1-b4c5-c4e121ec5cd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of qubits =  10\n",
            "number of quantum layers =  2\n",
            "number of angles (learnable parameters of quantum circuit) = 20\n",
            " \n",
            "batch_size = 64\n",
            "\n",
            "Epoch 1 ---------------------------------- \n",
            "\n",
            "train accuracy: 0.031,  train loss: 3.788\n",
            "test  accuracy: 0.04,  test  loss: 3.822\n",
            "\n",
            "Epoch 2 ---------------------------------- \n",
            "\n",
            "train accuracy: 0.274,  train loss: 3.108\n",
            "test  accuracy: 0.24,  test  loss: 3.325\n",
            "\n",
            "Epoch 3 ---------------------------------- \n",
            "\n",
            "train accuracy: 0.507,  train loss: 2.606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(A_Train, label='train set')\n",
        "plt.plot(A_Test, label='test set')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(L_Train, label='train set')\n",
        "plt.plot(L_Test, label='test set')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2GoaFOS5BxYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = np.random.choice(len(test_dataset))\n",
        "\n",
        "x = test_dataset[idx][0]\n",
        "print(f'x of {x.shape} :')\n",
        "plt.imshow(x[0], cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "print(f'true label = y = {test_dataset[idx][1]}\\n')\n",
        "\n",
        "\n",
        "out_ = model(x.view(1, 1, 28, 28)).detach().flatten()\n",
        "prob = F.softmax(out_, dim=0)\n",
        "pred = prob.argmax().item()\n",
        "print(f'predicted label = {pred}\\n')\n",
        "\n",
        "plt.stem(np.arange(10), prob)\n",
        "plt.ylabel('probability')\n",
        "plt.xlabel('class labels')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nHP5SDoACIXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "784+28*5+144"
      ],
      "metadata": {
        "id": "ALbuTf98CKjT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}