{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashishar/q_character/blob/main/Devanagari_with_qnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlUHdpeR9L6F",
        "outputId": "57164e1f-622f-4d53-f328-5eca10c1ce5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torchvision is already installed.\n"
          ]
        }
      ],
      "source": [
        "# !pip install torchvision\n",
        "# !pip install qiskit-machine-learning\n",
        "import importlib\n",
        "\n",
        "# Check if torchvision is installed\n",
        "try:\n",
        "    importlib.import_module('torchvision')\n",
        "    print(\"torchvision is already installed.\")\n",
        "except ImportError:\n",
        "    print(\"torchvision is not installed. Installing...\")\n",
        "    # Install torchvision using pip\n",
        "    try:\n",
        "        import pip\n",
        "        pip.main(['install', 'torchvision'])\n",
        "        print(\"torchvision installed successfully.\")\n",
        "    except Exception as e:\n",
        "        print(\"Error occurred while installing torchvision:\", str(e))\n",
        "\n",
        "# try:\n",
        "#     importlib.import_module('qiskit')\n",
        "#     print(\"qiskit is already installed.\")\n",
        "# except ImportError:\n",
        "#     print(\"qiskit is not installed. Installing...\")\n",
        "#     # Install torchvision using pip\n",
        "#     try:\n",
        "#         import pip\n",
        "#         pip.main(['install', 'qiskit'])\n",
        "#         print(\"qiskit installed successfully.\")\n",
        "#     except Exception as e:\n",
        "#         print(\"Error occurred while installing qiskit:\", str(e))\n",
        "\n",
        "# try:\n",
        "#     importlib.import_module('qiskit_machine_learning')\n",
        "#     print(\"qiskit-machine-learning is already installed.\")\n",
        "# except ImportError:\n",
        "#     print(\"qiskit-machine-learning is not installed. Installing...\")\n",
        "#     # Install torchvision using pip\n",
        "#     try:\n",
        "#         import pip\n",
        "#         pip.main(['install', 'qiskit-machine-learning'])\n",
        "#         print(\"qiskit-machine-learning installed successfully.\")\n",
        "#     except Exception as e:\n",
        "#         print(\"Error occurred while installing qiskit-machine-learning:\", str(e))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Change directory to the desired location where the file is stored.\n",
        "%cd /content/drive/MyDrive/\n",
        "\n",
        "# Import the file named quantum_circuit_simulator.py\n",
        "import quantum_circuit_simulator\n"
      ],
      "metadata": {
        "id": "XeGiH98DbAsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: I want to download devanagari character dataset from Kaggle.\n",
        "\n",
        "!pip install kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/drive/MyDrive/devanagari/kaggle.json ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download --force -d rishianand/devanagari-character-set\n",
        "!unzip \"/content/drive/My Drive/devanagari-character-set.zip\" -d \"/content/data\""
      ],
      "metadata": {
        "id": "Ip8-RV8ec6Z8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import Compose, ToTensor\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# Define transformations if necessary\n",
        "transform = Compose([\n",
        "    ToTensor(),  # Convert images to tensor\n",
        "    # Add more transformations as needed\n",
        "])\n",
        "\n",
        "# Load the dataset\n",
        "dataset = ImageFolder('/content/data', transform=transform)\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "# Create a DataLoader\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Now you can iterate over the DataLoader in your training loop\n",
        "\n"
      ],
      "metadata": {
        "id": "p8vLL8o4gppz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader.shape"
      ],
      "metadata": {
        "id": "cC2LhVlRkVEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "def imshow(img):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    img = img.numpy().transpose((1, 2, 0))  # Convert from Tensor image\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    img = img * std + mean  # Unnormalize\n",
        "    img = np.clip(img, 0, 1)  # Clip to make sure valid image\n",
        "    plt.imshow(img)\n",
        "    plt.pause(0.001)  # Pause a bit so that plots are updated\n",
        "\n",
        "def show_images(dataloader, classes, num_images=5):\n",
        "    \"\"\"Function to show images with labels from a dataloader\"\"\"\n",
        "    dataiter = iter(dataloader)\n",
        "    images, labels = next(dataiter)  # Use Python's built-in next() function\n",
        "\n",
        "    # Plot images\n",
        "    plt.figure(figsize=(15, 3))  # Adjust the size as needed\n",
        "    for idx in range(num_images):\n",
        "        ax = plt.subplot(1, num_images, idx + 1)\n",
        "        imshow(images[idx])\n",
        "        ax.set_title('Label: {}'.format(classes[labels[idx]]))\n",
        "        ax.axis('off')  # Hide axes ticks\n",
        "    plt.show()\n",
        "\n",
        "# Ensure that 'train_loader' has been created properly from an ImageFolder or similar utility\n",
        "# This assumes you have a list of classes stored somewhere. If you use ImageFolder it might look like this:\n",
        "classes = dataset.classes  # Adjust depending on how you've setup your DataLoader\n",
        "\n",
        "# Now call the function to visualize the images\n",
        "show_images(train_loader, classes, num_images=5)\n"
      ],
      "metadata": {
        "id": "zN1GUL0piTBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "szarnisTeiik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: mount gdrive and import a file named quantum_circuit_simulator.py\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Change directory to the desired location where the file is stored.\n",
        "%cd /content/drive/MyDrive/\n",
        "\n",
        "# Import the file named quantum_circuit_simulator.py\n",
        "import quantum_circuit_simulator\n"
      ],
      "metadata": {
        "id": "ZhwNEDV8-F6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time, copy\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data.dataset import random_split\n",
        "\n",
        "\n",
        "from quantum_circuit_simulator import quantum_circuit"
      ],
      "metadata": {
        "id": "kY3y6UeQ9X1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tf8Zv3l_-YL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the transform to normalize the data\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Load the MNIST dataset\n",
        "\n",
        "mnist_dataset= datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "\n",
        "# Select 1000 random images from the dataset\n",
        "random_indices = np.random.choice(len(mnist_dataset), size=13000, replace=False)\n",
        "reduced_dataset = torch.utils.data.Subset(mnist_dataset, random_indices)\n",
        "\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(reduced_dataset, [10000, 3000])\n",
        "\n",
        "\n",
        "# Create a DataLoader for the random subset\n",
        "batch_size = 64\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Load the MNIST dataset\n",
        "testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Select 1000 random images from the dataset\n",
        "random_indices = np.random.choice(len(testset), size=3000, replace=False)\n",
        "test_dataset = torch.utils.data.Subset(testset, random_indices)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "hRftFpIc9jcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = np.random.choice(len(train_dataset))\n",
        "\n",
        "# Access the data and label using the selected index\n",
        "x, y = train_dataset[idx]\n",
        "\n",
        "# Display the image\n",
        "print(f'x of {x.shape} :')\n",
        "plt.imshow(x.squeeze(), cmap='gray')  # Assuming MNIST images are grayscale (1 channel)\n",
        "plt.show()\n",
        "\n",
        "# Print the true label\n",
        "print(f'true label = y = {y}\\n')\n",
        "\n",
        "# Print the minimum and maximum pixel values\n",
        "print(f'(x_min, x_max) =  {x.min().item(), round(x.max().item(), 3)}')"
      ],
      "metadata": {
        "id": "Za6lcRN8_UsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"    # Get gpu or cpu device for training\n",
        "print(f\"Using {device} device\\n\")\n",
        "\n",
        "import torchvision.transforms.functional as TF\n",
        "from skimage.feature import hog\n",
        "\n",
        "\n",
        "\n",
        "# Define a function to compute HOG features for an image\n",
        "def compute_hog_features(image):\n",
        "    features, _ = hog(image, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True)\n",
        "\n",
        "    return features\n",
        "\n",
        "#=====================================================================================\n",
        "\n",
        "\n",
        "class QNN(torch.nn.Module):                              # Define model\n",
        "    def __init__(self, n, L):                            # number of qubits = n, number of quantum layers = L\n",
        "        super().__init__()\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        angles = torch.empty((L, n), dtype=torch.float64)\n",
        "        torch.nn.init.uniform_(angles, -0.01, 0.01)\n",
        "        self.angles = torch.nn.Parameter(angles)                   # it makes angles learnable parameters\n",
        "\n",
        "        # self.fc1 = nn.Linear(1024, 1024)\n",
        "        # self.fc2 = nn.Linear(784,512)\n",
        "        # self.fc3 = nn.Linear(512, 1024)\n",
        "\n",
        "        self.linear = nn.Linear(2**n, 10)                          # classical linear layer\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        #x = F.pad(x, (2 ,2, 2, 2), \"constant\", 0)                  # (left, right, top, bottom) padding\n",
        "        x_projection = torch.sum(x, dim=1).to(device)  # Calculate x-axis projection\n",
        "        #x_projection = x_projection / torch.norm(x_projection, p=1)\n",
        "        y_projection = torch.sum(x, dim=2).to(device)  # Calculate x-axis projection\n",
        "        #y_projection = y_projection / torch.norm(y_projection, p=1)\n",
        "        #angle projection\n",
        "        rotated_images1 = TF.rotate(x,30).to(device)\n",
        "        rotated_images2 = TF.rotate(x,45).to(device)\n",
        "        rotated_images3 = TF.rotate(x,60).to(device)\n",
        "\n",
        "        #rotated projections\n",
        "        rotated_projection1=torch.sum(rotated_images1, dim=2).to(device)\n",
        "        rotated_projection2=torch.sum(rotated_images2, dim=2).to(device)\n",
        "        rotated_projection3=torch.sum(rotated_images3, dim=2).to(device)\n",
        "\n",
        "        #rotated_images = torch.sum(torch.stack([TF.rotate(img, angle) for img in inputs]))\n",
        "        x_image=x.cpu().numpy()\n",
        "        hog_features = [compute_hog_features(np.squeeze(image)) for image in x_image]\n",
        "        hog_features_tensor = torch.tensor(np.array(hog_features), dtype=torch.float32).to(device)\n",
        "\n",
        "\n",
        "        x = self.flatten(x)\n",
        "        x = x[:, :-16]\n",
        "\n",
        "        # print(\"sizes \",x.shape, y_projection.shape, rotated_projection1.shape,rotated_projection2.shape,\n",
        "        #      rotated_projection3.shape,hog_features_tensor.shape)\n",
        "\n",
        "        combined_projection=torch.cat((x,y_projection.squeeze(), rotated_projection1.squeeze(),rotated_projection2.squeeze(),rotated_projection3.squeeze(),hog_features_tensor), dim=1)\n",
        "\n",
        "        #print(\"combined \", combined_projection.shape)\n",
        "        #x = self.flatten(x)\n",
        "        combined_projection /= torch.linalg.norm(x.clone(), ord=2, dim=1, keepdim=True)   # L2 normalization to change x --> |x⟩\n",
        "\n",
        "        # combined_projection = torch.sigmoid(self.fc1(combined_projection))\n",
        "        # x1 = torch.sigmoid(self.fc2(x1))\n",
        "        # x1 = torch.sigmoid(self.fc3(x1))\n",
        "\n",
        "        '''initializing parameterized quantum circuits (PQC)'''\n",
        "\n",
        "        qc = quantum_circuit(num_qubits = n, state_vector = combined_projection.T)   # each column is a feature-vector of an example\n",
        "        for l in range(L):\n",
        "            qc.Ry_layer(self.angles[l].to(torch.cfloat))           # rotation part of lth quantum layer\n",
        "            qc.cx_linear_layer()                                   # entangling part of lth quantum layer\n",
        "\n",
        "        'after passing through the PQC, measurement on the output-ket in the computational basis'\n",
        "        x = torch.real(qc.probabilities())               # each column is a probabilities-vector for an example\n",
        "                                                         # x.shape = (dim, batch size)\n",
        "\n",
        "        #print(torch.sum(x, dim=0))                      # to see whether probabilities add up to 1 or not\n",
        "\n",
        "        x = self.linear(x.T)                             # x.shape = (batch size, 10),  classical linear layer\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "Kulr9lBq_jxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def performance_estimate(dataset, model, loss_fn, train_or_test):\n",
        "    '''this function computes accuracy and loss of a model on the training or test set'''\n",
        "    data_size = len(dataset)\n",
        "\n",
        "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n",
        "    num_batches = len(dataloader)\n",
        "\n",
        "    model.eval()\n",
        "    loss, accuracy = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            accuracy += (pred.argmax(1) == y).sum().item()\n",
        "            loss += loss_fn(pred, y).item()\n",
        "    accuracy /= data_size                                            # accuracy lies in the interval [0, 1]\n",
        "    loss /= num_batches\n",
        "    print(f\"{train_or_test} accuracy: {round(accuracy, 3)},  {train_or_test} loss: {round(loss,3)}\")\n",
        "    return accuracy, loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def one_epoch(model, loss_fn, optimizer, train_dataset, test_dataset, batch_size):\n",
        "\n",
        "    A_train, L_train, A_test, L_test = [], [], [], []\n",
        "\n",
        "    dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        out = model(X)                             # Perform a single forward pass\n",
        "        loss = loss_fn(out, y)\n",
        "\n",
        "        optimizer.zero_grad()                      # Clear gradients\n",
        "        loss.backward()                            # Derive gradients, backpropagation\n",
        "        optimizer.step()                           # Update parameters based on gradients\n",
        "\n",
        "\n",
        "        if batch % batch_size == 0:\n",
        "            #As training progress, computing and appending loss and accuracy of the model on train and test set\n",
        "            accuracy_train, loss_train = performance_estimate(train_dataset, model, loss_fn, 'train')\n",
        "            accuracy_test, loss_test = performance_estimate(test_dataset, model, loss_fn, 'test ')\n",
        "            print()\n",
        "\n",
        "            A_train.append(accuracy_train)\n",
        "            L_train.append(loss_train)\n",
        "            A_test.append(accuracy_test)\n",
        "            L_test.append(loss_test)\n",
        "\n",
        "            #print(f\"train loss: {round(loss,3)}\")\n",
        "\n",
        "    return A_train, L_train, A_test, L_test\n",
        "\n",
        "\n",
        "\n",
        "def training(train_dataset, test_dataset, batch_size, n, L, lr_, weight_decay_, epochs):\n",
        "\n",
        "    model = QNN(n=n, L=L).to(device)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr_, weight_decay=weight_decay_)\n",
        "\n",
        "    A_Train, L_Train, A_Test, L_Test = [], [], [], []\n",
        "    for t in range(epochs):\n",
        "        print(f\"Epoch {t+1} ---------------------------------- \\n\")\n",
        "        #As training progress, computing and appending loss and accuracy of the model on train and test set\n",
        "        A_train, L_train, A_test, L_test = one_epoch(model, loss_fn, optimizer, train_dataset, test_dataset, batch_size)\n",
        "        A_Train += A_train\n",
        "        L_Train += L_train\n",
        "        A_Test += A_test\n",
        "        L_Test += L_test\n",
        "\n",
        "        #accuracy, loss = performance_estimate(test_dataset, model, loss_fn, 'test ')\n",
        "\n",
        "    model_state_dict = model.state_dict()           # for saving or loading the trained model\n",
        "\n",
        "    return A_Train, L_Train, A_Test, L_Test, model_state_dict"
      ],
      "metadata": {
        "id": "VYomaJwMBp2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "n = 10\n",
        "dim = 2**n              # dimension of the n-qubit Hilbert space\n",
        "L = 2\n",
        "\n",
        "n_angs = n*L\n",
        "\n",
        "print(\"number of qubits = \", n)\n",
        "print(\"number of quantum layers = \", L)\n",
        "print(f\"number of angles (learnable parameters of quantum circuit) = {n_angs}\\n \")\n",
        "\n",
        "#--------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "batch_size = 64\n",
        "print(f'batch_size = {batch_size}\\n')\n",
        "\n",
        "\n",
        "#----------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "A_Train, L_Train, A_Test, L_Test, model_state_dict = training(train_dataset, test_dataset, batch_size=batch_size, n=n, L=L,\n",
        "                                                              lr_=0.01, weight_decay_=1e-10, epochs=25)\n",
        "\n",
        "\n",
        "print(f' ~~~~~ training is done ~~~~~\\n')"
      ],
      "metadata": {
        "id": "Ogr-wkCNBuJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(A_Train, label='train set')\n",
        "plt.plot(A_Test, label='test set')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(L_Train, label='train set')\n",
        "plt.plot(L_Test, label='test set')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2GoaFOS5BxYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = np.random.choice(len(test_dataset))\n",
        "\n",
        "x = test_dataset[idx][0]\n",
        "print(f'x of {x.shape} :')\n",
        "plt.imshow(x[0], cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "print(f'true label = y = {test_dataset[idx][1]}\\n')\n",
        "\n",
        "\n",
        "out_ = model(x.view(1, 1, 28, 28)).detach().flatten()\n",
        "prob = F.softmax(out_, dim=0)\n",
        "pred = prob.argmax().item()\n",
        "print(f'predicted label = {pred}\\n')\n",
        "\n",
        "plt.stem(np.arange(10), prob)\n",
        "plt.ylabel('probability')\n",
        "plt.xlabel('class labels')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nHP5SDoACIXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "784+28*5+144"
      ],
      "metadata": {
        "id": "ALbuTf98CKjT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}