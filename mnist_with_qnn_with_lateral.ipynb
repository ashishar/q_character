{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashishar/q_character/blob/main/mnist_with_qnn_with_lateral.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LlUHdpeR9L6F",
        "outputId": "59029cdc-c75c-467a-e185-420a9ca625cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torchvision is already installed.\n",
            "qiskit is already installed.\n"
          ]
        }
      ],
      "source": [
        "# !pip install torchvision\n",
        "# !pip install qiskit-machine-learning\n",
        "import importlib\n",
        "\n",
        "# Check if torchvision is installed\n",
        "try:\n",
        "    importlib.import_module('torchvision')\n",
        "    print(\"torchvision is already installed.\")\n",
        "except ImportError:\n",
        "    print(\"torchvision is not installed. Installing...\")\n",
        "    # Install torchvision using pip\n",
        "    try:\n",
        "        import pip\n",
        "        pip.main(['install', 'torchvision'])\n",
        "        print(\"torchvision installed successfully.\")\n",
        "    except Exception as e:\n",
        "        print(\"Error occurred while installing torchvision:\", str(e))\n",
        "\n",
        "try:\n",
        "    importlib.import_module('qiskit')\n",
        "    print(\"qiskit is already installed.\")\n",
        "except ImportError:\n",
        "    print(\"qiskit is not installed. Installing...\")\n",
        "    # Install torchvision using pip\n",
        "    try:\n",
        "        import pip\n",
        "        pip.main(['install', 'qiskit'])\n",
        "        print(\"qiskit installed successfully.\")\n",
        "    except Exception as e:\n",
        "        print(\"Error occurred while installing qiskit:\", str(e))\n",
        "\n",
        "# try:\n",
        "#     importlib.import_module('qiskit_machine_learning')\n",
        "#     print(\"qiskit-machine-learning is already installed.\")\n",
        "# except ImportError:\n",
        "#     print(\"qiskit-machine-learning is not installed. Installing...\")\n",
        "#     # Install torchvision using pip\n",
        "#     try:\n",
        "#         import pip\n",
        "#         pip.main(['install', 'qiskit-machine-learning'])\n",
        "#         print(\"qiskit-machine-learning installed successfully.\")\n",
        "#     except Exception as e:\n",
        "#         print(\"Error occurred while installing qiskit-machine-learning:\", str(e))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: mount gdrive and import a file named quantum_circuit_simulator.py\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Change directory to the desired location where the file is stored.\n",
        "%cd /content/drive/MyDrive/\n",
        "\n",
        "# Import the file named quantum_circuit_simulator.py\n",
        "import quantum_circuit_simulator\n"
      ],
      "metadata": {
        "id": "ZhwNEDV8-F6f",
        "outputId": "81d232ff-2f37-4dd8-cb4c-5faf883a9329",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time, copy\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data.dataset import random_split\n",
        "\n",
        "\n",
        "from quantum_circuit_simulator import quantum_circuit"
      ],
      "metadata": {
        "id": "kY3y6UeQ9X1c"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tf8Zv3l_-YL-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the transform to normalize the data\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Load the MNIST dataset\n",
        "\n",
        "mnist_dataset= datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "# Select 1000 random images from the dataset\n",
        "random_indices = np.random.choice(len(mnist_dataset), size=13000, replace=False)\n",
        "reduced_dataset = torch.utils.data.Subset(mnist_dataset, random_indices)\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(reduced_dataset, [10000, 3000])\n",
        "\n",
        "\n",
        "# Create a DataLoader for the random subset\n",
        "batch_size = 64\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Load the MNIST dataset\n",
        "testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Select 1000 random images from the dataset\n",
        "# random_indices = np.random.choice(len(testset), size=3000, replace=False)\n",
        "# test_dataset = torch.utils.data.Subset(testset, random_indices)\n",
        "\n",
        "# test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "hRftFpIc9jcy"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = np.random.choice(len(train_dataset))\n",
        "\n",
        "# Access the data and label using the selected index\n",
        "x, y = train_dataset[idx]\n",
        "\n",
        "# Display the image\n",
        "print(f'x of {x.shape} :')\n",
        "plt.imshow(x.squeeze(), cmap='gray')  # Assuming MNIST images are grayscale (1 channel)\n",
        "plt.show()\n",
        "\n",
        "# Print the true label\n",
        "print(f'true label = y = {y}\\n')\n",
        "\n",
        "# Print the minimum and maximum pixel values\n",
        "print(f'(x_min, x_max) =  {x.min().item(), round(x.max().item(), 3)}')"
      ],
      "metadata": {
        "id": "Za6lcRN8_UsZ",
        "outputId": "10dc14ba-ae3e-42cf-c2a9-a9876e184cf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x of torch.Size([1, 28, 28]) :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "true label = y = 1\n",
            "\n",
            "(x_min, x_max) =  (0.0, 0.996)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"    # Get gpu or cpu device for training\n",
        "print(f\"Using {device} device\\n\")\n",
        "\n",
        "import torchvision.transforms.functional as TF\n",
        "from skimage.feature import hog\n",
        "\n",
        "\n",
        "\n",
        "# Define a function to compute HOG features for an image\n",
        "def compute_hog_features(image):\n",
        "    features, _ = hog(image, orientations=12, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True)\n",
        "\n",
        "    return features\n",
        "\n",
        "#=====================================================================================\n",
        "\n",
        "\n",
        "class QNN(torch.nn.Module):                              # Define model\n",
        "    def __init__(self, n, L):                            # number of qubits = n, number of quantum layers = L\n",
        "        super().__init__()\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        angles = torch.empty((L, n), dtype=torch.float64)\n",
        "        torch.nn.init.uniform_(angles, -0.01, 0.01)\n",
        "        self.angles = torch.nn.Parameter(angles)                   # it makes angles learnable parameters\n",
        "\n",
        "        # self.fc1 = nn.Linear(1024, 1024)\n",
        "        # self.fc2 = nn.Linear(784,512)\n",
        "        # self.fc3 = nn.Linear(512, 1024)\n",
        "\n",
        "        self.linear = nn.Linear(2**n, 10)                          # classical linear layer\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x=x.squeeze(1)\n",
        "        #x = F.pad(x, (2 ,2, 2, 2), \"constant\", 0)                  # (left, right, top, bottom) padding\n",
        "        x_projection = torch.sum(x, dim=1).to(device)  # Calculate x-axis projection\n",
        "        #print(\"x_projection \",x_projection.shape, x.shape)\n",
        "        #x_projection = x_projection / torch.norm(x_projection, p=1)\n",
        "        y_projection = torch.sum(x, dim=2).to(device)  # Calculate x-axis projection\n",
        "        #y_projection = y_projection / torch.norm(y_projection, p=1)\n",
        "        #print(\"y_projection \",y_projection.shape)\n",
        "        #angle projection\n",
        "        rotated_images1 = TF.rotate(x,30).to(device)\n",
        "        rotated_images2 = TF.rotate(x,45).to(device)\n",
        "        rotated_images3 = TF.rotate(x,60).to(device)\n",
        "\n",
        "        #rotated projections\n",
        "        rotated_projection1=torch.sum(rotated_images1, dim=2).to(device)\n",
        "        rotated_projection2=torch.sum(rotated_images2, dim=2).to(device)\n",
        "        rotated_projection3=torch.sum(rotated_images3, dim=2).to(device)\n",
        "\n",
        "        #rotated_images = torch.sum(torch.stack([TF.rotate(img, angle) for img in inputs]))\n",
        "        x_image=x.cpu().numpy()\n",
        "        hog_features = [compute_hog_features(np.squeeze(image)) for image in x_image]\n",
        "        hog_features_tensor = torch.tensor(np.array(hog_features), dtype=torch.float32).to(device)\n",
        "        #print(hog_features_tensor.shape)\n",
        "\n",
        "        x = self.flatten(x)\n",
        "        x = x[:, :-92]\n",
        "\n",
        "        # print(\"sizes \",x.shape, y_projection.shape, rotated_projection1.shape,rotated_projection2.shape,\n",
        "        #      rotated_projection3.shape,hog_features_tensor.shape)\n",
        "\n",
        "        combined_projection=torch.cat((x,x_projection,y_projection, rotated_projection1,rotated_projection2,rotated_projection3,\n",
        "                                       torch.zeros(x.shape[0],0),hog_features_tensor), dim=1)\n",
        "\n",
        "        #print(\"combined \", combined_projection.shape)\n",
        "        #x = self.flatten(x)\n",
        "        combined_projection /= torch.linalg.norm(x.clone(), ord=2, dim=1, keepdim=True)   # L2 normalization to change x --> |x⟩\n",
        "\n",
        "        # combined_projection = torch.sigmoid(self.fc1(combined_projection))\n",
        "        # x1 = torch.sigmoid(self.fc2(x1))\n",
        "        # x1 = torch.sigmoid(self.fc3(x1))\n",
        "\n",
        "        '''initializing parameterized quantum circuits (PQC)'''\n",
        "\n",
        "        qc = quantum_circuit(num_qubits = n, state_vector = combined_projection.T)   # each column is a feature-vector of an example\n",
        "        for l in range(L):\n",
        "            qc.Ry_layer(self.angles[l].to(torch.cfloat))           # rotation part of lth quantum layer\n",
        "            qc.cx_linear_layer()                                   # entangling part of lth quantum layer\n",
        "\n",
        "        'after passing through the PQC, measurement on the output-ket in the computational basis'\n",
        "        x = torch.real(qc.probabilities())               # each column is a probabilities-vector for an example\n",
        "                                                         # x.shape = (dim, batch size)\n",
        "\n",
        "        #print(torch.sum(x, dim=0))                      # to see whether probabilities add up to 1 or not\n",
        "\n",
        "        x = self.linear(x.T)                           # x.shape = (batch size, 10),  classical linear layer\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "Kulr9lBq_jxr",
        "outputId": "77702f5f-aad6-4406-d52a-1499c70c3a65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def performance_estimate(dataset, model, loss_fn, train_or_test):\n",
        "    '''this function computes accuracy and loss of a model on the training or test set'''\n",
        "    data_size = len(dataset)\n",
        "\n",
        "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n",
        "    num_batches = len(dataloader)\n",
        "\n",
        "    model.eval()\n",
        "    loss, accuracy = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            accuracy += (pred.argmax(1) == y).sum().item()\n",
        "            loss += loss_fn(pred, y).item()\n",
        "    accuracy /= data_size                                            # accuracy lies in the interval [0, 1]\n",
        "    loss /= num_batches\n",
        "    print(f\"{train_or_test} accuracy: {round(accuracy, 3)},  {train_or_test} loss: {round(loss,3)}\")\n",
        "    return accuracy, loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def one_epoch(model, loss_fn, optimizer, train_dataset, test_dataset, batch_size):\n",
        "\n",
        "    A_train, L_train, A_test, L_test = [], [], [], []\n",
        "\n",
        "    dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        out = model(X)                             # Perform a single forward pass\n",
        "        loss = loss_fn(out, y)\n",
        "\n",
        "        optimizer.zero_grad()                      # Clear gradients\n",
        "        loss.backward()                            # Derive gradients, backpropagation\n",
        "        optimizer.step()                           # Update parameters based on gradients\n",
        "\n",
        "\n",
        "        if batch % batch_size == 0:\n",
        "            #As training progress, computing and appending loss and accuracy of the model on train and test set\n",
        "            accuracy_train, loss_train = performance_estimate(train_dataset, model, loss_fn, 'train')\n",
        "            accuracy_test, loss_test = performance_estimate(test_dataset, model, loss_fn, 'test ')\n",
        "            print()\n",
        "\n",
        "            A_train.append(accuracy_train)\n",
        "            L_train.append(loss_train)\n",
        "            A_test.append(accuracy_test)\n",
        "            L_test.append(loss_test)\n",
        "\n",
        "            #print(f\"train loss: {round(loss,3)}\")\n",
        "\n",
        "    return A_train, L_train, A_test, L_test\n",
        "\n",
        "\n",
        "\n",
        "def training(train_dataset, test_dataset, batch_size, n, L, lr_, weight_decay_, epochs):\n",
        "\n",
        "    model = QNN(n=n, L=L).to(device)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr_, weight_decay=weight_decay_)\n",
        "\n",
        "    A_Train, L_Train, A_Test, L_Test = [], [], [], []\n",
        "    for t in range(epochs):\n",
        "        print(f\"Epoch {t+1} ---------------------------------- \\n\")\n",
        "        #As training progress, computing and appending loss and accuracy of the model on train and test set\n",
        "        A_train, L_train, A_test, L_test = one_epoch(model, loss_fn, optimizer, train_dataset, test_dataset, batch_size)\n",
        "        A_Train += A_train\n",
        "        L_Train += L_train\n",
        "        A_Test += A_test\n",
        "        L_Test += L_test\n",
        "\n",
        "        #accuracy, loss = performance_estimate(test_dataset, model, loss_fn, 'test ')\n",
        "\n",
        "    model_state_dict = model.state_dict()           # for saving or loading the trained model\n",
        "\n",
        "    return A_Train, L_Train, A_Test, L_Test, model_state_dict"
      ],
      "metadata": {
        "id": "VYomaJwMBp2m"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "n = 10\n",
        "dim = 2**n              # dimension of the n-qubit Hilbert space\n",
        "L = 2\n",
        "\n",
        "n_angs = n*L\n",
        "\n",
        "print(\"number of qubits = \", n)\n",
        "print(\"number of quantum layers = \", L)\n",
        "print(f\"number of angles (learnable parameters of quantum circuit) = {n_angs}\\n \")\n",
        "\n",
        "#--------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "batch_size = 64\n",
        "print(f'batch_size = {batch_size}\\n')\n",
        "\n",
        "\n",
        "#----------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "A_Train, L_Train, A_Test, L_Test, model_state_dict = training(train_dataset, test_dataset, batch_size=batch_size, n=n, L=L,\n",
        "                                                              lr_=0.01, weight_decay_=1e-10, epochs=30)\n",
        "\n",
        "\n",
        "print(f' ~~~~~ training is done ~~~~~\\n')"
      ],
      "metadata": {
        "id": "Ogr-wkCNBuJl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48e23d33-6691-41a9-85eb-f61de1ade4f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of qubits =  10\n",
            "number of quantum layers =  2\n",
            "number of angles (learnable parameters of quantum circuit) = 20\n",
            " \n",
            "batch_size = 64\n",
            "\n",
            "Epoch 1 ---------------------------------- \n",
            "\n",
            "train accuracy: 0.134,  train loss: 2.207\n",
            "test  accuracy: 0.127,  test  loss: 2.206\n",
            "\n",
            "train accuracy: 0.829,  train loss: 0.69\n",
            "test  accuracy: 0.81,  test  loss: 0.72\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(A_Train, label='train set')\n",
        "plt.plot(A_Test, label='test set')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(L_Train, label='train set')\n",
        "plt.plot(L_Test, label='test set')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2GoaFOS5BxYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = np.random.choice(len(test_dataset))\n",
        "\n",
        "x = test_dataset[idx][0]\n",
        "print(f'x of {x.shape} :')\n",
        "plt.imshow(x[0], cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "print(f'true label = y = {test_dataset[idx][1]}\\n')\n",
        "\n",
        "\n",
        "out_ = model(x.view(1, 1, 28, 28)).detach().flatten()\n",
        "prob = F.softmax(out_, dim=0)\n",
        "pred = prob.argmax().item()\n",
        "print(f'predicted label = {pred}\\n')\n",
        "\n",
        "plt.stem(np.arange(10), prob)\n",
        "plt.ylabel('probability')\n",
        "plt.xlabel('class labels')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nHP5SDoACIXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "2048-1056+32\n"
      ],
      "metadata": {
        "id": "ALbuTf98CKjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M6EYGsPLwYk0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}